import numpy as np
import pandas as pd
import random as rd

# 初始化超参数
K = 4
W = 8
C = 500
sigma = 0.9 

class SupportVectorMachine():
    # 超参数初始化
    def __init__(self, K, W, C, sigma):
        self.K = K
        self.W = W
        self.C = C
        self.sigma = sigma
        self.k = self.rbf_kernel
    
    # ------------------------------预处理组件-----------------------------
    # 预处理函数，对数据集进行预处理和划分，随机选择数据-------------------
    def preprocessing(self, t_o_rate, v_t_rate):
        dataSet = pd.read_csv("diabetes.csv", header=0)
        # 2号列“血压”存在0值，属于缺失属性，使用KNN算法进行修复
        data = self.knn_revover(dataSet, 2)
        # 按照训练：其他，验证：测试的比例划分数据集
        train_data, others = self.boostraping(data, t_o_rate)
        test_data, validate_data = self.boostraping(others, v_t_rate)
        # 训练数据直接绑定，验证数据和测试数据外流
        x = np.array(train_data[:,:-1])
        y = np.array(train_data[:,-1])
        self.x = x
        self.y = y
        return validate_data, test_data

    # 修复函数：对缺失数据集的re_col列进行修复，完成后直接传回array--------
    def knn_revover(self, dataSet, re_col):
        # 在numpy的支持下进行运算
        data = np.array(dataSet[1:])
        # 记录需修复样本的编号
        number = [i for i in range(0,len(data)) if data[i][re_col]==0]
        # 标准化,跳过结果列
        mean_data = np.mean(data[:,:-1], axis=0)
        std_data = np.std(data[:,:-1], axis=0, ddof=1)
        data[:,:-1] = (data[:,:-1] - mean_data)/std_data
        # 根据标准化后的数据计算L1距离来选点
        # 对每个恢复点
        for i in number:
            # 创建副本，应该不会被
            point_i = list(data[i][:])
            point_i.pop(-1)
            point_i.pop(re_col)
            point_i = np.array(point_i)
            distances = []
            values = [[] for i in range(0,self.K)]
            # 计算到每个不需恢复点的L1距离，更新或取距离最小的相应位置
            for j in range(0, len(data)):
                if j in number:
                    continue
                point_j = list(data[j][:])
                # 计算距离时不考虑恢复需属性和标记
                point_j.pop(-1)
                point_j.pop(re_col)
                point_j = np.array(point_j)
                distance = sum(np.square(point_i - point_j))
                # 判断是否比distances每个值都小
                for dis in distances:
                    if dis < distance:
                        distance = -1
                        break
                if distance >= 0:
                    # 选中点的相应值
                    value = point_j[re_col]
                    # 如果距离数目已经达到了要求
                    if len(distances) == K:
                        # 如果这个距离早就存在
                        if distance in distances:
                            num = distances.index(distance)
                            values[num].append(value)
                        # 否则这个距离不存在，需要替换原有最长距离
                        else:
                            num = distances.index(max(distances))
                            distances[num] = distance
                            values[num] = [value,]
                    # 缺少的话直接补上
                    else:
                        distances.append(distance)
                        values.append([value,])
            # 找完了最小距离，计算re_col平均值
            recover = [sum(v)/len(values) for v in values]
            recover = sum(recover)/len(recover)
            data[i,re_col] = recover
        # 修复完毕，re_col列标准化后，返回修复后的数据集合data
        mean_re_col = np.mean(data[:,re_col], axis=0)
        std_re_col = np.std(data[:,re_col], axis=0)
        data[:,re_col] = (data[:,re_col] - mean_re_col)/std_re_col
        # 结果列0-1元素用0.1-0.9元素
        for i in range(0, len(data)):
            if data[i][-1] == 1:
                data[i][-1] = 0.9
            if data[i][-1] == 0:
                data[i][-1] = 0.1
        return np.array(data)

    # 自助法函数，把一个嵌套列表结构的数据按照比例分成a,b两部分------------
    def boostraping(self, data, rate):
        # 实现自助法选择数据，要求按照rate的比例得到数据集a
        a_numbers = []
        while len(a_numbers) < rate*len(data):
            add = rd.randint(0, len(data)-1)
            for i in range(0,len(a_numbers)):
                if add == a_numbers[i]:
                    add = -1
                    break
            if add != -1:
                a_numbers.append(add)
        a_data = [data[i] for i in a_numbers]
        # 剩下的数据分为b类
        b_numbers = [i for i in range(0, len(data)) if i not in a_numbers]
        b_data = [data[i] for i in b_numbers]
        return np.array(a_data), np.array(b_data)

    # -------------------------------训练组件------------------------------
    # 训练函数，根据训练集，核函数训练迭代---------------------------------
    def train(self):
        k = self.k
        x = self.x
        y = self.y
        # 参数初始化
        alpha = np.random.rand(len(x))
        # 保证约束条件，不妨用第一个来开刀
        alpha[0] = alpha[0] - sum([alpha[j]*y[j] for j in range(0,len(x))])/y[0]
        # 对偶问题的SMO算法求解，收敛后结束循环
        m = 0
        n = 0
        turn = 0
        # 当前解是否满足KKT条件
        safe = 1
        while turn < 1 or safe:
            # 优先选择违反KKT条件最严重的一项alpha，另一项目随机
            compare = [abs(alpha[i] - 0.5*self.C) for i in range(0,len(x))]
            m = compare.index(max(compare))
            n = rd.randint(0,len(x)-1)
            while m == n:
                n = rd.randint(0,len(x)-1)
            # 如果违反KKT趋势最严重的项仍然满足KKT，那就可以保证安全
            if alpha[m] >= 0 and alpha[m] <= self.C:
                safe = 0
            # 闭式解求m,n的优化
            new_m, new_n = self.SMO(alpha, m, n)
            # 检查是否收敛
            if abs(new_m - alpha[m]) + abs(new_n - alpha[n]) < 1:
                turn = turn + 1
            else:
                turn = 0
            alpha[m] = new_m
            alpha[n] = new_n
            print(m, n, alpha[m], alpha[n])
        # 计算一下模型的偏置
        b = 0
        for s in range(0, len(x)):
            b = b + y[s] - sum([alpha[j]*y[j]*k(x[j],x[s]) 
                for j in range(0,len(x))])
        b = b / len(x)
        # 动态绑定必须数据
        self.alpha = alpha
        self.b = b

    # SMO优化函数，返回单次SMO结果-----------------------------------------
    def SMO(self, alpha, m, n):
        k = self.k
        x = self.x
        y = self.y
        # 取得闭式解需要组件
        c = - alpha.dot(y) 
        c = c + alpha[m]*y[m] + alpha[n]*y[n]
        p1 = sum([alpha[j]*y[j]*k(x[n],x[j])
            for j in range(0,len(x)) if j!=m and j!=n])
        p2 = sum([alpha[j]*y[j]*k(x[m],x[j])
            for j in range(0,len(x)) if j!=m and j!=n])
        p3 = c*k(x[n], x[n])
        p4 = c*k(x[m], x[n])
        p5 = y[m]*(k(x[m],x[m]) + k(x[n],x[n]) - 2*k(x[m],x[n]))
        # 直接求出此时的闭式解，结果需要符合约束范围
        new = (p1-p2+p3-p4 + 1/y[m]-1/y[n])/p5
        # 仍旧要检查范围，合理限制有利于加快函数更新
        if new > self.C:
            new = c
        if new < 0:
            new = 0
        return new, (c - new*y[m])/y[n]

    # 高斯核函数-----------------------------------------------------------
    def rbf_kernel(self, xi, xj):
        result = np.exp(-sum(np.square(xi - xj))/(2*sigma*sigma))
        return result
        
    # -------------------------------验证组件------------------------------
    # 验证函数，根据验证数据选出最佳超参数（自适应过程）-------------------
    def validate(self, validate_data):
        k = self.k
        # 初始化迭代轮数和最小错误率
        error = 1
        turn = 0
        # 自适应迭代
        while turn < 1:
            turn = turn + 1
            # 选择超参数
            C = rd.randint(10,1000)
            sigma = rd.random()
            # 训练模型
            self.train()
            # 测试结果
            accuracy = self.test(validate_data)
            # 正确率有所提高便更新参数
            if 1 - accuracy < error:
                error = 1 - accuracy
                self.C = C
                self.sigma = sigma
        print("the accuracy of svm in validation is: %f" % (1.0-error))

    # -------------------------------测试组件------------------------------
    def test(self, test_data):
        k = self.k
        accuracy = 0
        for x_y in test_data:
            # 对测试集拆包
            x_y = list(x_y)
            y = x_y.pop()
            x = np.array(x_y)
            result = sum([self.alpha[j]*self.y[j]*k(self.x[j],x)
                for j in range(0,len(x))]) + self.b
            # 分类与实际一致
            if (y>result and y==0.9) or (y<result and y==0.1):
                accuracy = accuracy + 1
        # 统计出正确率
        accuracy = accuracy / len(test_data)
        return accuracy

def main():
    # 创建SVM实例
    svm = SupportVectorMachine(K, W, C, sigma)
    # 训练集：验证集：测试集 = 3：1：1，训练数据已经直接保留
    validate_data, test_data = svm.preprocessing(0.6, 0.5)
    # 训练得到最优参数训练
    svm.train()
    # 自适应得到最佳超参数
    svm.validate(validate_data)
    # 除了训练和测试过程中打印结果之外，最后再打印一次测试结果
    accuracy = svm.test(test_data)
    print("the supperparamenter are: C: %f; sigma: %f"
            % (svm.C, svm.sigma))
    print("the accuracy of svm in test is %f" % accuracy)

if __name__ == "__main__":
    main()
