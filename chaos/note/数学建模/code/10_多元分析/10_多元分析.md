# 10、多元分析

## 10.1、聚类分析

- Q聚类：利用合适的距离对样本聚类，通过不断的递归二分类来把样本展开为二叉树。
- R聚类：利用相关系数对变量聚类，使得减少变量个数，只选择有代表能力的变量。

### 实战

​	先使用R聚类选择合适属性，再使用Q聚类对样本进行聚类：

```matlab
%anli10_1_1.m
%R聚类，寻找变量之间的联系
clc, clear
%格式要求为:“对象*属性”的矩阵
a=load('gj.txt'); %把原始数据保存在纯文本文件gj.txt中
b=zscore(a); %数据标准化
r=corrcoef(b) %计算相关系数矩阵
%d=tril(1-r); d=nonzeros(d)'; %另外一种计算距离方法
d=pdist(b','correlation'); %计算相关系数导出的距离
z=linkage(d,'average');  %按类平均法聚类
h=dendrogram(z);  %画聚类图
set(h,'Color','k','LineWidth',1.3)  %把聚类图线的颜色改成黑色，线宽加粗
T=cluster(z,'maxclust',6)  %把变量划分成6类
for i=1:6
    tm=find(T==i);  %求第i类的对象
    tm=reshape(tm,1,length(tm)); %变成行向量
    fprintf('the %d(th) kind cinlude: %s\n',i,int2str(tm)); %显示分类结果
end
```

​	输出结果为：

```bash
the 1(th) kind cinlude: 1
the 2(th) kind cinlude: 2  3  4  5  6
the 3(th) kind cinlude: 9
the 4(th) kind cinlude: 7
the 5(th) kind cinlude: 8
the 6(th) kind cinlude: 10
```

​	之后在程序中，按照上面的结果选择合适的属性进行Q聚类分析：

```matlab
%Q聚类
clc,clear
load gj.txt   %把原始数据保存在纯文本文件gj.txt中
%在这里按照之前的结果选择合适的属性
gj(:,[3:6])=[]; %删除数据矩阵的第3列～第6列,即使用变量 1,2,7,8,9,10
gj=zscore(gj); %数据标准化
y=pdist(gj); %求对象间的欧氏距离,每行是一个对象
z=linkage(y,'average');  %按类平均法聚类
h=dendrogram(z);  %画聚类图
set(h,'Color','k','LineWidth',1.3)  %把聚类图线的颜色改成黑色，线宽加粗
for k=3:5
    fprintf('the result of dividing into %d groups：\n',k)
    T=cluster(z,'maxclust',k);  %把样本点划分成k类
    for i=1:k
      tm=find(T==i);  %求第i类的对象
      tm=reshape(tm,1,length(tm)); %变成行向量
      fprintf('the %d(th) kind includes: %s\n',i,int2str(tm)); %显示分类结果
    end
    if k==5
        break
    end
    fprintf('**********************************\n');
end
```

​	分别尝试把样本分为3、4、5类。

```bash
the result of dividing into 3 groups：
the 1(th) kind includes: 25
the 2(th) kind includes: 2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  26  27  28  29  30
the 3(th) kind includes: 1
**********************************
the result of dividing into 4 groups：
the 1(th) kind includes: 2  3
the 2(th) kind includes: 4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  26  27  28  29  30
the 3(th) kind includes: 25
the 4(th) kind includes: 1
**********************************
the result of dividing into 5 groups：
the 1(th) kind includes: 28  29  30
the 2(th) kind includes: 4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  26  27
the 3(th) kind includes: 2  3
the 4(th) kind includes: 25
the 5(th) kind includes: 1
```



## 10.2、PCA

​	基本思想：分解成比较少的低维正交向量来刻画总体，下面X为随即变量，寻找合适的权值c。

​	$$s=c_1x_1+c_2x_2+...+c_px_p$$

​	$$max Var(c_1X_1+c_2X_2+...+c_pX_p)r$$

​	$$c_1^2+c_2^2+...+c_p^2=1$$

​	创建主成分的时候，要满足条件：

1. 正交于所有主成分；
2. 使Var达到最大；
3. 满足标准化的约束条件(=1)；

### 确定主成分的个数

1. 受量纲影响，需要先标准化；
2. 使方差最大的PCA不需要转轴；
3. 主成分保留，用COV矩阵时一般放弃特征值小于1的部分；
4. 一般用于降维，所以只需要主成分累计贡献率有70%~80%；

### PCA回归分析

​	为了克服最小二乘的不稳定性，将原来的回归自变量转化为主成分；在这个空间进行回归分析，再把结果还原到原来的空间。

​	下面是对水泥4个属性的分析，需要选择合适的主成分，选择其中的3个主成分可以发现最后的标准差，PCA回归比直接回归更小，说明PCA更稳定。

```matlab
%ex10_5
%PCA回归分析
clc,clear
load sn.txt  %把原始的x1,x2,x3,x4,y的数据保存在纯文本文件sn.txt中
[m,n]=size(sn);
x0=sn(:,[1:n-1]);y0=sn(:,n); 
hg1=[ones(m,1),x0]\y0;   %计算普通最小二乘法回归系数
hg1=hg1' %变成行向量显示回归系数,其中第1个分量是常数项，其它按x1,...,xn排序
fprintf('y=%f',hg1(1)); %开始显示普通最小二乘法回归结果
for i=2:n
    if hg1(i)>0  
       fprintf('+%f*x%d',hg1(i),i-1);
    else
       fprintf('%f*x%d',hg1(i),i-1)
    end
end
fprintf('\n')  
r=corrcoef(x0)  %计算相关系数矩阵
xd=zscore(x0);  %对设计矩阵进行标准化处理
yd=zscore(y0);  %对y0进行标准化处理
[vec1,lamda,rate]=pcacov(r) %vec1为r的特征向量，lamda为r的特征值，rate为各个主成分的贡献率
f=repmat(sign(sum(vec1)),size(vec1,1),1); %构造与vec1同维数的元素为±1的矩阵
vec2=vec1.*f %修改特征向量的正负号，使得特征向量的所有分量和为正
contr=cumsum(rate) %计算累积贡献率，第i个分量表示前i个主成分的贡献率
df=xd*vec2;  %计算所有主成分的得分
num=input('Please choose the number of PCs:')   %通过累积贡献率交互式选择主成分的个数
hg21=df(:,[1:num])\yd  %主成分变量的回归系数,这里由于数据标准化，回归方程的常数项为0
hg22=vec2(:,1:num)*hg21  %标准化变量的回归方程系数
hg23=[mean(y0)-std(y0)*mean(x0)./std(x0)*hg22, std(y0)*hg22'./std(x0)]  %计算原始变量回归方程的系数
fprintf('y=%f',hg23(1)); %开始显示主成分回归结果
for i=2:n
    if hg23(i)>0
        fprintf('+%f*x%d',hg23(i),i-1);
    else
        fprintf('%f*x%d',hg23(i),i-1);
    end
end
fprintf('\n')
%下面计算两种回归分析的剩余标准差
rmse1=sqrt(sum((hg1(1)+x0*hg1(2:end)'-y0).^2)/(m-n))   %拟合了n个参数
rmse2=sqrt(sum((hg23(1)+x0*hg23(2:end)'-y0).^2)/(m-num)) %拟合了num个参数
```

## 10.3、因子分析

​	因子分析是PCA的推广，因子与PCA中的主成分相对应；因子是一个抽象概念。

​	如：对N个学生的分数X进行分析，对第i学生

​	$X_i=\mu_i+\alpha_{i1}F_1+\alpha_{i2}F_2+...+\alpha_{i5}F_5+\varepsilon_i,i=0,1,2,...,N$

​	其中$\alpha_i$称为因子载荷，表示权重；$\mu_i$是总平均；$\varepsilon_i$是学生i无法用这五个因子评价的部分，通常$\varepsilon ～N(0,\sigma^2)$。	 

​	首要任务：估计因子载荷$\alpha_i$和方差$\sigma^2$，给$F_i$一个合理解释，如果没有合理解释，就需要因子旋转来做进一步解释。

### 模型P241

​	$X-\mu=\Lambda F+\varepsilon$

​	$Cov(X)=\Lambda\Lambda^T+diag(\sigma_1^2,\sigma_2^2,...,\sigma_m^2)$

​	其中$\Lambda$是载荷因子，$F$是共享因子；可以看出其中方差的值越小，则共享因子的成分越多。

### 统计意义P242

​	$1=\sum_{j=1}^m\alpha_{ij}^2+\sigma_i^2$

​	如果上面和式部分非常靠近1，则特殊方差方差很小；表示因子分析的效果好。

### 估计方法

#### 1、PCA

​	已知相关系数矩阵，特征值$\lambda$和标准特征向量$\eta$

​	$\Lambda=[\sqrt \lambda_1 \eta_1,\sqrt \lambda_2 \eta_2,...,\sqrt \lambda_m \eta_m]$

​	$\sigma_i^2=1-\sum_{j=1}^m\alpha_{ij}^2$

```matlab
clc,clear
r=[1.000 0.577 0.509 0.387 0.462
   0.577 1.000 0.599 0.389 0.322
   0.509 0.599 1.000 0.436 0.426
   0.387 0.389 0.436 1.000 0.523
   0.462 0.322 0.426 0.523 1.000];
%下面利用相关系数矩阵求主成分解，vec1的列为r的特征向量，即主成分的系数
[vec1,val,rate]=pcacov(r);%val为r的特征值，rate为各个主成分的贡献率
f1=repmat(sign(sum(vec1)),size(vec1,1),1);%构造与vec1同维数的元素为±1的矩阵
vec2=vec1.*f1; %修改特征向量的正负号，使得每个特征向量的分量和为正
f2=repmat(sqrt(val)',size(vec2,1),1);  %构造与vec2同维数的矩阵
a=vec2.*f2    %构造全部因子的载荷矩阵，见（10.27）式 
a1=a(:,1)   %提出一个因子的载荷矩阵
tcha1=diag(r-a1*a1')   %计算一个因子的特殊方差
a2=a(:,[1,2])  %提出两个因子的载荷矩阵
tcha2=diag(r-a2*a2')  %计算两个因子的特殊方差
ccha2=r-a2*a2'-diag(tcha2)  %求两个因子时的残差矩阵
con=cumsum(rate)     %求累积贡献率
```

#### 2、主因子法

​	修正PCA，

​	$R=\Lambda\Lambda^T+D$

​	$R^*=\Lambda\Lambda^T=R-D$

​	R*为约相关系数矩阵

#### 3、极大似然估计

​	上面的都不靠谱，应该用这个。

​	其中r是相关系数矩阵，

```matlab
%%%PCA估计
clc,clear
r=[1 1/5 -1/5;1/5 1 -2/5;-1/5 -2/5 1];
%下面利用相关系数矩阵求主成分解，val的列为r的特征向量，即主成分的系数
[vec,val,con]=pcacov(r) %val为r的特征值，con为各个主成分的贡献率
num=input('请选择公共因子的个数：');  %交互式选取主因子的个数
f1=repmat(sign(sum(vec)),size(vec,1),1);
vec=vec.*f1;     %特征向量正负号转换
f2=repmat(sqrt(val)',size(vec,1),1);
a=vec.*f2   %计算因子载荷矩阵
aa=a(:,1:num)   %提出两个主因子的载荷矩阵
s1=sum(aa.^2)   %计算对X的贡献率，实际上等于对应的特征值
s2=sum(aa.^2,2)  %计算共同度

%%%主因子法估计
clc,clear
r=[1 1/5 -1/5;1/5 1 -2/5;-1/5 -2/5 1];
n=size(r,1); rt=abs(r); %求矩阵r所有元素的绝对值
rt(1:n+1:n^2)=0; %把rt矩阵的对角线元素换成0
rstar=r; %R*初始化
rstar(1:n+1:n^2)=max(rt'); %把矩阵rstar的对角线元素换成rt矩阵各行的最大值 
%下面利用R*矩阵求主因子解，vec1的列为矩阵rstar的特征向量
[vec1,val,rate]=pcacov(rstar)  %val为rstar的特征值，rate为各个主成分的贡献率
f1=repmat(sign(sum(vec1)),size(vec1,1),1);
vec2=vec1.*f1     %特征向量正负号转换
f2=repmat(sqrt(val)',size(vec2,1),1);
a=vec2.*f2   %计算因子载荷矩阵
num=input('请选择公共因子的个数：');  %交互式选取主因子的个数
aa=a(:,1:num)   %提出num个因子的载荷矩阵
s1=sum(aa.^2)   %计算对X的贡献率
s2=sum(aa.^2,2)  %计算共同度

%%%极大似然估计
clc,clear
r=[1 1/5 -1/5;1/5 1 -2/5;-1/5 -2/5 1];
[Lambda,Psi] = factoran(r,1,'xtype','cov') %Lambda返回的是因子载荷矩阵，Psi返回的是特殊方差
```

### 因子旋转

​	如果公共因子的数学含义不明确，就要对$\Lambda$矩阵进行旋转，使每行每列的元素平方值向0或1分化。

​	取正交矩阵T对做逆时针或者顺时针旋转。

​	$X-\mu=(\Lambda T)(T^TF)+\varepsilon$

​	

### 因子得分

​	需要因子做回归分析，就需要对公共因子进行测度；给出每个公共因子的具体值。

​	使用加权最小二乘法、回归法。



## 10.4、判别分析

​	把每个样本分类到正确的总体中。

### 距离判别

​	在统计分布中，欧几里德距离不再适用；应该考虑马氏距离。

### Fisher判别

​	将不易分类的数据投影到某个方向上来分离类与类；多元观测投影到一元观测

### Bayes判别



## 10.5、典型相关分析

​	$X=[x_1,x_2,...,x_p],Y=[y_1,y_2,...,y_q]$

​	研究两组变量的相关关系，共有pq个相关系数，繁琐而且没有抓住本质；使用类似主成分的思想找到合适的线性组合。

​	可以分别提取主成分，每次各自提取出一个合成一组，提取合适次数。

​	$u=\rho^TX,v=\gamma^TY$

​	如上线性组合成为两个随机变量

​	

## 10.6、对应分析

​	R型因子分析、Q型因子分析；R型针对变量，Q型针对样本。